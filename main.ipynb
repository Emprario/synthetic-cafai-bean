{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef209a3bfe588cf6",
   "metadata": {},
   "source": [
    "## Importation of important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f994c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "RD_STATE=42\n",
    "Z_ALPHA = 0.5\n",
    "\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfd95dc9c4dc1d8",
   "metadata": {},
   "source": [
    "## Get the datasets from kaggle\n",
    "\n",
    "> By doing so, you can get the datasets only with the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b226738c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download latest version\n",
    "sch_path = kagglehub.dataset_download(\"uom190346a/global-coffee-health-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", sch_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb6a536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "sch_db = pd.read_csv(sch_path + '/synthetic_coffee_health_10000.csv')\n",
    "sch_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fc7246",
   "metadata": {},
   "source": [
    "# DataViz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95431f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dataset\n",
    "for col in sch_db.columns:\n",
    "    print(col, sch_db[col].isnull().sum(), end=\" \")\n",
    "    print(sch_db[col].unique())\n",
    "\n",
    "# Check dataset\n",
    "sch_db.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b87f9ebdf7f8961",
   "metadata": {},
   "source": [
    "## **Data Cleaning**\n",
    "* Goal: Fix or remove incorrect, corrupted, or incomplete data.\n",
    "* Typical Tasks:\n",
    "    * Handling missing values (e.g., imputation or deletion)\n",
    "        * Done (removed NaN in Health Issues column)\n",
    "    * Removing duplicates and irrelevant variables\n",
    "        * Done (removed ID column)\n",
    "    * Fixing data entry errors (e.g., inconsistent capitalization or typos)\n",
    "        * Done (none)\n",
    "    * Correcting inconsistencies (e.g., \"USA\" vs. \"United States\") and incomplete values\n",
    "        * Done (none)\n",
    "    * Handling outliers (depending on the use case)\n",
    "        * TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36356ea7c03b9dce",
   "metadata": {},
   "source": [
    "#### 1. Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ab2422f1124842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether there is missing values or not\n",
    "sch_db.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f277d8c1225f694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are missing values in 'Health Issues'\n",
    "# Let's assume rows without data in 'Health Issues' represent a person with good health\n",
    "sch_db['Health_Issues'].fillna('No', inplace=True)\n",
    "print(sch_db['Health_Issues'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dc76d2ae4370df",
   "metadata": {},
   "source": [
    "#### 2. Removing duplicates and irrelevant variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af35f69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the \"other\" gender since non-sense\n",
    "sch_db = sch_db[sch_db['Gender'] != 'Other']\n",
    "# Severe is deleting it is too \"niche\"\n",
    "sch_db = sch_db[sch_db['Health_Issues'] != 'Severe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f0630e9efffa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, the 'ID' column is irrelevant for the ML algorithm, so we can just drop it\n",
    "sch_db = sch_db.drop([\"ID\"], axis=1)\n",
    "\n",
    "sch_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4488f3",
   "metadata": {},
   "source": [
    "#### 3.4.5. Fixing data entry errors, Inconsistencies, Handling outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e62e6dc58fd66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check whether there are data entry errors, inconsistencies or outliers in the DB\n",
    "for col in sch_db.columns:\n",
    "    print(\"=====\" + col + \"=====\")\n",
    "    if len(x:= sch_db[col].value_counts()) < 50:\n",
    "        print(x)\n",
    "    print(sch_db[col].describe())\n",
    "    print(\"\\n\")\n",
    "    \n",
    "# high Physical_Activity_Hours !\n",
    "\n",
    "# It seems there are no mistypes values, no inconsistencies and not outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb79b899cd4a89cd",
   "metadata": {},
   "source": [
    "## **Data Preprocessing**\n",
    "\n",
    "* Goal: Prepare raw data for modelling or analysis.\n",
    "* Includes data cleaning, plus additional transformations, such as:\n",
    "    * Encoding categorical variables (e.g., one-hot encoding)\n",
    "    * Feature scaling (e.g., normalization, standardization)\n",
    "    * Feature selection/extraction\n",
    "    * Data transformation (e.g., log transformations, binning)\n",
    "    * Handling imbalanced datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8816e051cb138ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erase z_alpha case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f7203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class balance\n",
    "sch_db['Health_Issues'].value_counts(normalize=True).mul(100).round(2).astype(str) + '%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9caa5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch dataset for testing around 10%\n",
    "test_db = sch_db.sample(frac=0.1, random_state=RD_STATE) \n",
    "test_db.to_csv(\"./test_data.csv\")\n",
    "test_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff29b043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the records in the main db\n",
    "try:\n",
    "    sch_db = sch_db.drop(test_db.index)\n",
    "except KeyError:\n",
    "    print(\"Rows already delted\")\n",
    "sch_db.to_csv(\"./training_data.csv\")\n",
    "sch_db"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
